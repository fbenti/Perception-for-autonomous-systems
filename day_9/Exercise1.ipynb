{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global registration with RANSAC\n",
    "We are going to use open3d (http://www.open3d.org/) to handle  pointclouds and generation of pointclouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# helper function for drawing if you want it to be more clear which is which set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = True):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    \n",
    "    if(recolor):\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None):\n",
    "        source_temp.transform(transformation)\n",
    "    \n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "#                                       zoom=0.3412,\n",
    "#                                       front=[0.4257, -0.2125, -0.8795],\n",
    "#                                       lookat=[2.6172, 2.0475, 1.532],\n",
    "#                                       up=[-0.0694, -0.9768, 0.2024]\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to read in our pointclouds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding features in pointclouds\n",
    "When working on point clouds it can be benefitial work on a downsampled version of the point cloud.\n",
    "you can use [```pointcloudname.voxel_down_sample()```](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html) where pointcloud is the name of your point cloud object.\n",
    "\n",
    "Voxel downsampling uses a regular voxel grid to create a uniformly downsampled point cloud from an input point cloud. It is often used as a pre-processing step for many point cloud processing tasks. The algorithm operates in two steps:\n",
    "\n",
    "    1. Points are bucketed into voxels.\n",
    "    2. Each occupied voxel generates exactly one point by averaging all points inside.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We also need to estimate the normals of the pointcloud points using [```pointcloudname.estimate_normals()```](http://www.open3d.org/docs/latest/python_api/open3d.geometry.PointCloud.html)\n",
    "\n",
    "    estimate_normals: computes the normal for every point. The function finds adjacent points and calculates the principal axis of the adjacent points using covariance analysis.\n",
    "    \n",
    "    The function takes an instance of KDTreeSearchParamHybrid class as an argument. The two key arguments radius = 0.1 and max_nn = 30 specifies search radius and maximum nearest neighbor. It has 10cm of search radius, and only considers up to 30 neighbors to save computation time.\n",
    "\n",
    "And finally find fpfh features or correspondance of the downsampled point clouds.\n",
    "[```o3d.pipelines.registration.compute_fpfh_feature()```](http://www.open3d.org/docs/latest/python_api/open3d.pipelines.registration.compute_fpfh_feature.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Downsample and find features here\n",
    "####\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "    source = o3d.io.read_point_cloud(\"ICP/r1.pcd\")\n",
    "    target = o3d.io.read_point_cloud(\"ICP/r3.pcd\")\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registrations(source, target, np.identity(4))\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    draw_registrations(source_down, target_down, np.identity(4))\n",
    "    \n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.05 # means 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print a normal vector of the 0th point\n",
      "[-0.00179454 -0.98362967 -0.1801928 ]\n",
      "Print the normal vectors of the first 10 points\n",
      "[[-1.79453577e-03 -9.83629674e-01 -1.80192798e-01]\n",
      " [-9.87445606e-01  1.15696826e-01 -1.07542643e-01]\n",
      " [-5.74133348e-02 -9.55844085e-01 -2.88211371e-01]\n",
      " [ 3.11833525e-02 -9.98178981e-01 -5.16364159e-02]\n",
      " [ 4.13321781e-01 -3.78813730e-01 -8.28049071e-01]\n",
      " [ 3.71122831e-02 -9.68741831e-01 -2.45279316e-01]\n",
      " [-6.51199096e-02 -4.58519659e-01  8.86295165e-01]\n",
      " [-3.82736451e-03 -4.14415227e-01  9.10079871e-01]\n",
      " [ 2.62305291e-01 -9.10724355e-01 -3.19025209e-01]\n",
      " [-6.91152360e-04 -9.84510839e-01 -1.75322363e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Estimated normal vectors can be retrieved from the normals variable of downpcd.\n",
    "print(\"Print a normal vector of the 0th point\")\n",
    "print(source_down.normals[0])\n",
    "# Normal vectors can be transformed as a numpy array using np.asarray.\n",
    "print(\"Print the normal vectors of the first 10 points\")\n",
    "print(np.asarray(source_down.normals)[:10, :])\n",
    "# To check out other variables, please use help(downpcd)\n",
    "# help(source_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ransac\n",
    "We will now attempt to use ransac to do a global registration of the two poinclouds.\n",
    "\n",
    "Using the function [```o3d.pipelines.registration.registration_ransac_based_on_feature_matching```](http://www.open3d.org/docs/latest/python_api/open3d.pipelines.registration.registration_ransac_based_on_feature_matching.html) from open3d\n",
    "    \n",
    "    RANSACConvergenceCriteria. It defines the maximum number of RANSAC iterations and the confidence probability.\n",
    "    The larger these two numbers are, the more accurate the result is, but also the more time the algorithm takes.\n",
    "\n",
    "Try to find the transformation from r1 to r2.\n",
    "Attempt with point to point and point to plane\n",
    "```Python\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "```\n",
    "\n",
    "When using ransac focus on the arguments below the rest are optional\n",
    "```Python\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    distance_threshold,\n",
    "    point_to_point)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.050,\n",
      "   we use a liberal distance threshold 0.075.\n",
      "RegistrationResult with fitness=2.312860e-01, inlier_rmse=4.313868e-02, and correspondence_set size of 241\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Call RANSAC here\n",
    "####\n",
    "\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "    \n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    \n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "   \n",
    "    ransac_result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "                source_down,\n",
    "                target_down,\n",
    "                source_fpfh,\n",
    "                target_fpfh,\n",
    "                True, # mutual_filter\n",
    "                distance_threshold, # max_correspondence_distance \n",
    "                o3d.pipelines.registration.TransformationEstimationPointToPoint(False), # estimation_method\n",
    "#                 3, # ransac_n\n",
    "#                 ([\n",
    "#                 o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "#                 o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "#                 ]), # checkers\n",
    "#                 o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999)\n",
    "                )\n",
    "    return ransac_result\n",
    "\n",
    "ransac_result = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "print(ransac_result)\n",
    "draw_registrations(source_down, target_down, ransac_result.transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "### A)\n",
    "    Can you get a decent transformation from r1 to r3?\n",
    "### B)\n",
    "    with the following checkers can you get better results from RANSAC? Try tweaking the parameters of them Can you make Point to Plane work do not spend too long on this if you cant skip it. (I was not able to get a good fit)\n",
    "\n",
    "You can also try tweaking the voxel_size\n",
    "```Python\n",
    "corr_length = 0.9\n",
    "distance_threshold = voxel_size * 1.5\n",
    "\n",
    "c0 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "c1 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "c2 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "cecker_list = [c0,c1,c2]\n",
    "\n",
    "ransac_result = o3d.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_sample, target_sample, \n",
    "    source_fpfh, target_fpfh, \n",
    "    True,\n",
    "    distance_threshold,\n",
    "    point_to_point,\n",
    "    checkers = checker_list)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=2.303263e-01, inlier_rmse=4.379523e-02, and correspondence_set size of 240\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "corr_length = 0.9\n",
    "distance_threshold = voxel_size * 1.5\n",
    "\n",
    "c0 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "c1 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "c2 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "checker_list = [c0,c1,c2]\n",
    "\n",
    "ransac_result2 = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_down, target_down, \n",
    "    source_fpfh, target_fpfh, \n",
    "    True,\n",
    "    distance_threshold,\n",
    "    point_to_point,\n",
    "    checkers = checker_list)\n",
    "\n",
    "print(ransac_result2)\n",
    "draw_registrations(source_down, target_down, ransac_result2.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
