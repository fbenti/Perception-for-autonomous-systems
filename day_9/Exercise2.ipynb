{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local registration with ICP\n",
    "\n",
    "    In the RGBD folder we have the first 400 images from one of the datasets from: (http://redwood-data.org/indoor_lidar_rgbd/download.html)\n",
    "\n",
    "\n",
    "    If you want to display directly in jupyter notebook replace the **draw_registrations** with this:\n",
    "\n",
    "```python\n",
    "from open3d import JVisualizer\n",
    "\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "        source_temp = copy.deepcopy(source)\n",
    "        target_temp = copy.deepcopy(target)\n",
    "        if(recolor):\n",
    "            source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "            target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "        if(transformation is not None):\n",
    "            source_temp.transform(transformation)\n",
    "        visualizer = JVisualizer()\n",
    "        visualizer.add_geometry(source_temp)\n",
    "        visualizer.add_geometry(target_temp)\n",
    "        visualizer.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open3d.j_visualizer import JVisualizer\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "# Helper function to draw registrations (reccomended)\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "        source_temp = copy.deepcopy(source)\n",
    "        target_temp = copy.deepcopy(target)\n",
    "        if(recolor):\n",
    "            source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "            target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "        if(transformation is not None):\n",
    "            source_temp.transform(transformation)\n",
    "        o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "        \n",
    "def draw_registrations1(source, target, transformation = None, recolor = False):\n",
    "        source_temp = copy.deepcopy(source)\n",
    "        target_temp = copy.deepcopy(target)\n",
    "        if(recolor):\n",
    "            source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "            target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "        if(transformation is not None):\n",
    "            source_temp.transform(transformation)\n",
    "        visualizer = JVisualizer()\n",
    "        visualizer.add_geometry(source_temp)\n",
    "        visualizer.add_geometry(target_temp)\n",
    "        visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pointclouds from image data\n",
    "Now we are going to try to create our own pointclouds from rgb and depth images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in images. We have images 000000 - 0000400\n",
    "color_raw0 = o3d.io.read_image(\"RGBD/color/000000.jpg\")\n",
    "depth_raw0 = o3d.io.read_image(\"RGBD/depth/000000.png\")\n",
    "\n",
    "color_raw1 = o3d.io.read_image(\"RGBD/color/000005.jpg\")\n",
    "depth_raw1 = o3d.io.read_image(\"RGBD/depth/000005.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pointclouds from rgb + depth images.\n",
    "\n",
    "If you set *convert_rgb_to_intensity = False* you will retain the colors from the rgb image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd_image0 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw0, \n",
    "    depth_raw0, \n",
    "    convert_rgb_to_intensity = False)\n",
    "\n",
    "rgbd_image1 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw1, \n",
    "    depth_raw1, \n",
    "    convert_rgb_to_intensity = True)\n",
    "\n",
    "#show images\n",
    "fig= plt.figure(figsize=(15,15))\n",
    "plt.subplot(221)\n",
    "plt.title('Redwood grayscale0 image')\n",
    "plt.imshow(rgbd_image0.color)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('Redwood depth0 image')\n",
    "plt.imshow(rgbd_image0.depth)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.title('Redwood grayscale1 image')\n",
    "plt.imshow(rgbd_image1.color)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.title('Redwood depth1 image')\n",
    "plt.imshow(rgbd_image1.depth)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images to Pointcloud\n",
    "Now we create point clouds from the rgbd images we just created.\n",
    "\n",
    "\n",
    "Here we use **PinholeCameraIntrinsicParameters.PrimeSenseDefault** as default camera parameter. \n",
    "\n",
    "It has image resolution 640x480, focal length (fx, fy) = (525.0, 525.0), and optical center (cx, cy) = (319.5, 239.5). \n",
    "\n",
    "An identity matrix is used as the default extrinsic parameter. pcd.transform applies an up-down flip transformation on the point cloud for better visualization purpose.\n",
    "\n",
    "\n",
    "If it becomes too slow you can downsample the pointcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source pointcloud\n",
    "camera = o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\n",
    "\n",
    "source = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image0, camera)\n",
    "\n",
    "# Target pointcloud\n",
    "target = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image1, camera)\n",
    "\n",
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "source.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "target.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "# Draw\n",
    "draw_registrations(source, target, recolor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of pointclouds\n",
    "\n",
    "Before we can run ICP we evaluate our source and target pointclouds. This gives us a measure to see if we need a better initial transformation or not.\n",
    "\n",
    "The function evaluate_registration calculates two main metrics:\n",
    "\n",
    "    1. fitness: measures the overlapping area (# of inlier correspondences / # of points in target). The higher the better.\n",
    "    2. inlier_rmse: measures the RMSE of all inlier correspondences. The lower the better.\n",
    "(http://www.open3d.org/docs/latest/tutorial/Basic/icp_registration.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "threshold = 0.03\n",
    "trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "#Evaluate registration\n",
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICP\n",
    "\n",
    "Now try to call icp with your point clouds and your initial transformation.\n",
    "\n",
    "Initially we use:\n",
    "```Python\n",
    "point_to_plane =  o3d.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "icp_result = o3d.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    point_to_plane)\n",
    "\n",
    "```\n",
    "   registration_icp is called with a different parameter TransformationEstimationPointToPlane. \n",
    "   Internally, this class implements functions to compute the residuals and Jacobian matrices of the point-to-plane ICP objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# ICP: PointToPlane\n",
    "###\n",
    "def ICP_point2plane(source, target, threshold, trans_init):\n",
    "    \n",
    "    point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "    source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5, max_nn=30), fast_normal_computation = True)\n",
    "    target.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5, max_nn=30), fast_normal_computation = True)\n",
    "\n",
    "    icp_result = o3d.pipelines.registration.registration_icp(source,\n",
    "                                                             target,\n",
    "                                                             threshold,\n",
    "                                                             trans_init,\n",
    "                                                             point_to_plane)\n",
    "#     print(icp_result)\n",
    "#     print(\"Transformation is:\")\n",
    "#     print(icp_result.transformation)\n",
    "    return icp_result.transformation\n",
    "\n",
    "# draw_registrations(source, target, icp_result.transformation, True) # not original color\n",
    "# draw_registrations(source, target, icp_result.transformation) # original color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# ICP: PointToPoint\n",
    "###\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "\n",
    "source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5, max_nn=30), fast_normal_computation = True)\n",
    "target.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5, max_nn=30), fast_normal_computation = True)\n",
    "\n",
    "icp_result = o3d.pipelines.registration.registration_icp(source,\n",
    "                                                         target,\n",
    "                                                         threshold,\n",
    "                                                         trans_init,\n",
    "                                                         point_to_point)\n",
    "\n",
    "print(icp_result)\n",
    "print(\"Transformation is:\")\n",
    "print(icp_result.transformation)\n",
    "\n",
    "draw_registrations(source, target, icp_result.transformation, True) # not original color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exersices\n",
    "\n",
    "### A)\n",
    "If you increase the amount of steps from the original image so from i.e. 000000-000001 to 00000-000300 what happens?\n",
    "### B)\n",
    "Can you tweak the parameters *threshold* and *trans_init* to combat some of the ill effects that starts appearing?\n",
    "### C)\n",
    "Again try to use \n",
    "```Python\n",
    "point_to_plane =  o3d.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "reg_p2p = o3d.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    point_to_plane)\n",
    "```\n",
    "\n",
    "This requires you to find the normals for each point cloud use:\n",
    "```python\n",
    "    source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                            max_nn=30),fast_normal_computation=True)\n",
    "```\n",
    "Compare the resulting translations of the two methods is one better than the other?\n",
    "### D)\n",
    "Extend this and try to see how much of the bedroom you can reconstruct from the rgb and depth images.\n",
    "you can extend a pointcloud by new = source + target remember to resample the point cloud some times so it does not get too large down_source = source.voxel_down_sample(voxel_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'transformation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-93fbf833a3b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mdown_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoxel_down_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoxel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mdraw_registrations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdown_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdown_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0micp_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'transformation'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Source pointcloud\n",
    "camera = o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\n",
    "\n",
    "# Parameters\n",
    "threshold = 0.03\n",
    "trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "images_color = glob.glob('RGBD/color/*.jpg')\n",
    "assert images_color\n",
    "\n",
    "images_depth = glob.glob('RGBD/depth/*.png')\n",
    "assert images_depth\n",
    "\n",
    "color_raw0 = o3d.io.read_image(images_color[0])\n",
    "depth_raw0 = o3d.io.read_image(images_depth[0])\n",
    "\n",
    "rgbd_image0 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw0, \n",
    "    depth_raw0, \n",
    "    convert_rgb_to_intensity = False)\n",
    "\n",
    "source = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image0, camera)\n",
    "down_source = source.voxel_down_sample(voxel_size=0.05)\n",
    "\n",
    "for fname in images_color:\n",
    "    # read the first image        \n",
    "    \n",
    "    color_raw = o3d.io.read_image(images_color[1])\n",
    "    depth_raw = o3d.io.read_image(images_depth[1])\n",
    "\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color_raw, \n",
    "        depth_raw, \n",
    "        convert_rgb_to_intensity = False)\n",
    "    \n",
    "    # Target pointcloud\n",
    "    target = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, camera)\n",
    "    down_target = target.voxel_down_sample(voxel_size = 0.05)\n",
    "    \n",
    "    icp_result = ICP_point2plane(down_source, target, threshold, trans_init)\n",
    "    \n",
    "    down_source += target\n",
    "    down_source = source.voxel_down_sample(voxel_size = 0.05)\n",
    "\n",
    "draw_registrations(down_source, down_target, icp_result.transformation, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_color = glob.glob('RGBD/color/*.jpg')\n",
    "assert images_color\n",
    "\n",
    "images_depth = glob.glob('RGBD/depth/*.png')\n",
    "assert images_depth\n",
    "\n",
    "color_raw0 = o3d.io.read_image(images_color[0])\n",
    "depth_raw0 = o3d.io.read_image(images_depth[0])\n",
    "\n",
    "rgbd_image0 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw0, \n",
    "    depth_raw0, \n",
    "    convert_rgb_to_intensity = False)\n",
    "source0 = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image0, camera)\n",
    "\n",
    "color_raw1 = o3d.io.read_image(images_color[55])\n",
    "depth_raw1 = o3d.io.read_image(images_depth[55])\n",
    "\n",
    "rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw, \n",
    "    depth_raw, \n",
    "    convert_rgb_to_intensity = False)\n",
    "target = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, camera)\n",
    "\n",
    "source = source0 + target\n",
    "\n",
    "draw_registrations(source0, source, recolor = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
