{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r,c = img1.shape\n",
    "    img1 = cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\n",
    "    img2 = cv2.cvtColor(img2,cv2.COLOR_GRAY2BGR)\n",
    "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv2.line(img1, (x0,y0), (x1,y1), color,1)\n",
    "        img1 = cv2.circle(img1,tuple(pt1),5,color,-1)\n",
    "        img2 = cv2.circle(img2,tuple(pt2),5,color,-1)\n",
    "    return img1,img2\n",
    "\n",
    "def epipolar_SIFT(img1, img2, n_matches):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    kp_img = cv2.drawKeypoints(img1, kp2, img1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    #plt.figure(figsize = (10,10))\n",
    "    #plt.imshow(kp_img)\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.match(des1,des2)\n",
    "\n",
    "    # Sort them in the order of their distance (i.e. best matches first).\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    nb_matches = n_matches\n",
    "\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for m in matches[:nb_matches]:\n",
    "        good.append(m)\n",
    "        pts1.append(kp1[m.queryIdx].pt)\n",
    "        pts2.append(kp2[m.trainIdx].pt)\n",
    "\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC)\n",
    "\n",
    "    # We select only inlier points\n",
    "    pts1 = pts1[mask.ravel() == 1]\n",
    "    pts2 = pts2[mask.ravel() == 1]\n",
    "    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2 ,F)\n",
    "    lines1 = lines1.reshape(-1, 3)\n",
    "    img5, img6 = drawlines(img1, img2, lines1, pts1, pts2)\n",
    "\n",
    "    # Find epilines corresponding to points in left image (first image) and\n",
    "    # drawing its lines on right image\n",
    "    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n",
    "    lines2 = lines2.reshape(-1, 3)\n",
    "    img3, img4 = drawlines(img2, img1, lines2, pts2, pts1)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, constrained_layout=True, figsize=(10,10))\n",
    "    axs[0, 0].imshow(img4)\n",
    "    axs[0, 0].set_title('left keypoints')\n",
    "    axs[0, 1].imshow(img6)\n",
    "    axs[0, 1].set_title('right keypoints')\n",
    "    axs[1, 0].imshow(img5)\n",
    "    axs[1, 0].set_title('left epipolar lines')\n",
    "    axs[1, 1].imshow(img3)\n",
    "    axs[1, 1].set_title('right epipolar lines')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_vertical = 6\n",
    "nb_horizontal = 9\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((nb_horizontal*nb_vertical,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nb_vertical,0:nb_horizontal].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints_l = [] # 3d point in real world space\n",
    "imgpoints_l = [] # 2d points in image plane.\n",
    "\n",
    "images_l = glob.glob('rs/left-*.png')\n",
    "assert images_l\n",
    "\n",
    "\n",
    "for fname in images_l:\n",
    "    img = cv2.imread(fname)\n",
    "    h, w = img.shape[:2]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, corners = cv2.findChessboardCorners(img, (nb_vertical,nb_horizontal),  None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints_l.append(objp)\n",
    "\n",
    "        imgpoints_l.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (nb_vertical,nb_horizontal), corners,ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(50)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(np.asarray(objpoints_l).shape)\n",
    "print(np.asarray(imgpoints_l).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints_r = [] # 3d point in real world space\n",
    "imgpoints_r = [] # 2d points in image plane.\n",
    "\n",
    "images_r = glob.glob('rs/right-*.png')\n",
    "assert images_r\n",
    "\n",
    "\n",
    "for fname in images_r:\n",
    "    img = cv2.imread(fname)\n",
    "    h, w = img.shape[:2]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, corners = cv2.findChessboardCorners(img, (nb_vertical,nb_horizontal),  None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints_r.append(objp)\n",
    "\n",
    "        imgpoints_r.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (nb_vertical,nb_horizontal), corners,ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(50)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(np.asarray(objpoints_r).shape)\n",
    "print(np.asarray(imgpoints_r).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_l, mtx_l, dist_l, rvecs_l, tvecs_l = cv2.calibrateCamera(objpoints_l, imgpoints_l, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_r, mtx_r, dist_r, rvecs_r, tvecs_r = cv2.calibrateCamera(objpoints_r, imgpoints_r, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_l = cv2.imread('rs/left-0013.png')\n",
    "h,  w = img_l.shape[:2]\n",
    "newcameramtx_l, roi_l = cv2.getOptimalNewCameraMatrix(mtx_l,dist_l,(w,h),1,(w,h))\n",
    "print (newcameramtx_l)\n",
    "img_r = cv2.imread('rs/right-0013.png')\n",
    "h,  w = img_r.shape[:2]\n",
    "newcameramtx_r, roi_r = cv2.getOptimalNewCameraMatrix(mtx_r,dist_r,(w,h),1,(w,h))\n",
    "print (newcameramtx_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_l = cv2.undistort(img_l, mtx_l, dist_l, None, None)\n",
    "dst_r = cv2.undistort(img_r, mtx_r, dist_r, None, None)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(18,18))\n",
    "ax[0, 0].imshow(img_l[...,[2,1,0]])\n",
    "ax[0, 0].set_title('Original image left')\n",
    "ax[0, 1].imshow(dst_l[...,[2,1,0]])\n",
    "ax[0, 1].set_title('Undistorted image left')\n",
    "ax[1, 0].imshow(img_r[...,[2,1,0]])\n",
    "ax[1, 0].set_title('Original image right')\n",
    "ax[1, 1].imshow(dst_r[...,[2,1,0]])\n",
    "ax[1, 1].set_title('Undistorted image right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"rs/left-0013.png\", 0)\n",
    "img2 = cv2.imread(\"rs/right-0013.png\", 0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18,18))\n",
    "ax[0].imshow(img1, cmap='gray')\n",
    "ax[0].set_title('Left image')\n",
    "ax[1].imshow(img2, cmap='gray')\n",
    "ax[1].set_title('Right image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "kp_img = cv2.drawKeypoints(img1, kp2, img1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(kp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher()\n",
    "matches = bf.match(des1,des2)\n",
    "\n",
    "# Sort them in the order of their distance (i.e. best matches first).\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "nb_matches = 200\n",
    "\n",
    "good = []\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "\n",
    "for m in matches[:nb_matches]:\n",
    "    good.append(m)\n",
    "    pts1.append(kp1[m.queryIdx].pt)\n",
    "    pts2.append(kp2[m.trainIdx].pt)\n",
    "\n",
    "pts1 = np.int32(pts1)\n",
    "pts2 = np.int32(pts2)\n",
    "    \n",
    "\"\"\"\n",
    "Implement findFundamentalMat here:\n",
    "F, mask = ...\n",
    "\"\"\"\n",
    "F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC)\n",
    "\n",
    "# We select only inlier points\n",
    "pts1 = pts1[mask.ravel() == 1]\n",
    "pts2 = pts2[mask.ravel() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2 ,F)\n",
    "lines1 = lines1.reshape(-1, 3)\n",
    "img5, img6 = drawlines(img1, img2, lines1, pts1, pts2)\n",
    "\n",
    "# Find epilines corresponding to points in left image (first image) and\n",
    "# drawing its lines on right image\n",
    "lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n",
    "lines2 = lines2.reshape(-1, 3)\n",
    "img3, img4 = drawlines(img2, img1, lines2, pts2, pts1)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, constrained_layout=True, figsize=(10,10))\n",
    "axs[0, 0].imshow(img4)\n",
    "axs[0, 0].set_title('left keypoints')\n",
    "axs[0, 1].imshow(img6)\n",
    "axs[0, 1].set_title('right keypoints')\n",
    "axs[1, 0].imshow(img5)\n",
    "axs[1, 0].set_title('left epipolar lines')\n",
    "axs[1, 1].imshow(img3)\n",
    "axs[1, 1].set_title('right epipolar lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx_l, dist_l, mtx_r, dist_r, R, T, E, F = cv2.stereoCalibrate(objpoints_l, imgpoints_l, imgpoints_r, mtx_l, dist_l, mtx_r, dist_r, img1.shape)\n",
    "#ret, mtx_l, dist_l, mtx_r, dist_r, R, T, E, F = cv2.stereoCalibrate(objp, imgpoints_l, imgpoints_r, mtx_l, dist_l, mtx_r, dist_r, image_size)\n",
    "R1, R2, P1, P2, Q, roi_left, roi_right = cv2.stereoRectify(mtx_l, dist_l, mtx_r, dist_r, img1.shape, R, T, flags=cv2.CALIB_ZERO_DISPARITY, alpha=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,  w = img1.shape[:2]\n",
    "xmap_l, ymap_l = cv2.initUndistortRectifyMap(mtx_l, dist_l, R1, mtx_l, (w,h), cv2.CV_32FC1)\n",
    "xmap_r, ymap_r = cv2.initUndistortRectifyMap(mtx_r, dist_r, R1, mtx_r, (w,h), cv2.CV_32FC1)\n",
    "\n",
    "dst_l = cv2.undistort(img1, mtx_l, dist_l, None, None)\n",
    "dst_r = cv2.undistort(img2, mtx_r, dist_r, None, None)\n",
    "\n",
    "rect_l = cv2.remap(dst_l, xmap_l, ymap_l, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)\n",
    "rect_r = cv2.remap(dst_r, xmap_r, ymap_r, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18,18))\n",
    "ax[0].imshow(rect_l, cmap='gray')\n",
    "ax[0].set_title('Left image')\n",
    "ax[1].imshow(rect_r, cmap='gray')\n",
    "ax[1].set_title('Right image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epipolar_SIFT(rect_l, rect_r, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
